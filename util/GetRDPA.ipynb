{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fd1bee13-1aa0-4e17-86e8-a7ac16aaf5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "import warnings\n",
    "import time\n",
    "import json\n",
    "from shapely.geometry import shape\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "from owslib.wms import WebMapService\n",
    "import pandas as pd\n",
    "\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1202ac3a-5566-4c94-a0f4-8be186f20b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "wms = WebMapService('https://geo.weather.gc.ca/geomet?SERVICE=WMS' +\n",
    "                    '&REQUEST=GetCapabilities',\n",
    "                    version='1.3.0',\n",
    "                    timeout=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30862c9e-9a88-4e66-b2a5-047d1d5127a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "timeseriesfolder = \"2023_RDPA\"\n",
    "start_time = '2023-01-01T12:00'\n",
    "end_time = '2023-12-31T12:00'\n",
    "total_precip_shapefile = 'CaPA_grid_total_precip_2023-2023.shp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a29a5a1d-f0d6-44dd-ac0a-66e0d114ef4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = 24\n",
    "fmt = '%Y-%m-%dT%H:%M'\n",
    "start_time = datetime.strptime(start_time, fmt)\n",
    "end_time = datetime.strptime(end_time, fmt)\n",
    "\n",
    "timesteps = [start_time]\n",
    "while timesteps[-1] < end_time:\n",
    "    timesteps.append(timesteps[-1] + timedelta(hours=interval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bcd4a4d7-72a8-4960-a6fb-770fcdb9f720",
   "metadata": {},
   "outputs": [],
   "source": [
    "station = '07DD001'\n",
    "layer = 'RDPA.24F_PR'  # 24-hour precipitation accumulation\n",
    "crs = 'EPSG:4326'\n",
    "crs2 = 'ESRI:102001'\n",
    "folder = r'C:\\Users\\LeachJ\\Documents\\GIS DataBase\\HydrometricNetworkBasinPolygons'\n",
    "shapefile = os.path.join(folder, station[:2], station, f\"{station}_DrainageBasin_BassinDeDrainage.shp\")\n",
    "if not os.path.exists(shapefile):\n",
    "    shapefile = os.path.join(folder, station[:2], f'EC_{station}_1.shp')\n",
    "if os.path.exists(shapefile):\n",
    "    gdf_boundary = gpd.read_file(shapefile, engine='pyogrio', use_arrow=True).to_crs(crs2)\n",
    "gdf_boundary = gdf_boundary.buffer(7000)  # 7 km buffer\n",
    "gdf_boundary2 = gdf_boundary.to_crs(crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b227584-4335-4423-bbe3-131db3625702",
   "metadata": {},
   "outputs": [],
   "source": [
    "bbox = tuple(gdf_boundary2.total_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2e761abf-aba4-48bb-adcb-cac155ee8eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(wms[layer].boundingBoxWGS84)\n",
    "# print(wms[layer].dimensions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5685a360-f900-4be5-acc4-9f3ec92adff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-01-07 12:00:00 {}\n",
      "2023-03-11 12:00:00 {}\n",
      "2023-03-12 12:00:00 {}\n",
      "2023-03-13 12:00:00 {}\n",
      "2023-03-14 12:00:00 {}\n",
      "2023-08-01 12:00:00 {}\n",
      "2023-09-04 12:00:00 {}\n",
      "4.27522611618042\n"
     ]
    }
   ],
   "source": [
    "# Loop to carry out the requests and extract the probabilities\n",
    "def request(layer, timesteps, crs, bbox, feature_count, outfolder): \n",
    "    if not os.path.exists(outfolder):\n",
    "        os.mkdir(outfolder)\n",
    "    for timestep in timesteps:\n",
    "        outputfile = os.path.join(outfolder, f\"{timestep.strftime('%Y-%m-%d')}.shp\")\n",
    "        if not os.path.exists(outputfile):\n",
    "            # WMS GetFeatureInfo query\n",
    "            json_data = wms.getfeatureinfo(layers=[layer],\n",
    "                                           srs=crs,\n",
    "                                           bbox=bbox,\n",
    "                                           size=(30, 30),  # needed manual adjustment\n",
    "                                           format='image/jpeg',\n",
    "                                           query_layers=[layer],\n",
    "                                           info_format='application/json',\n",
    "                                           xy=(15, 25),  # needed manual adjustment\n",
    "                                           feature_count=feature_count,\n",
    "                                           time=str(timestep.isoformat()) + 'Z')\n",
    "            try:\n",
    "                features = json.loads(json_data.read().decode('utf-8'))['features']\n",
    "                geomlst = []\n",
    "                valulst = []\n",
    "                for feature in features:\n",
    "                    geomlst.append(feature['geometry'])\n",
    "                    valulst.append(feature['properties']['value'])\n",
    "        \n",
    "                gdf = gpd.GeoDataFrame()\n",
    "                geom = [shape(i) for i in geomlst]\n",
    "                gdf['values'] = np.float32(valulst)\n",
    "                idx = gdf['values'] == 9999.0\n",
    "                gdf['values'][idx] = np.nan\n",
    "                gdf = gdf.set_geometry(geom).set_crs(crs)\n",
    "                gdf.to_file(outputfile, engine='pyogrio', use_arrow=True)\n",
    "            except KeyError:\n",
    "                print(timestep, json.loads(json_data.read().decode('utf-8')))\n",
    "\n",
    "tic = time.time()\n",
    "request(layer, timesteps, crs, bbox, 8000, timeseriesfolder)\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5829992e-fd50-4f2f-9f80-53b52fa70739",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.78275871276855\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "for i, timestep in enumerate(timesteps):\n",
    "    shpfile = os.path.join(timeseriesfolder, f\"{timestep.strftime('%Y-%m-%d')}.shp\")\n",
    "    if os.path.exists(shpfile):\n",
    "        if i == 0:\n",
    "            gdf = gpd.read_file(shpfile, engine='pyogrio', use_arrow=True)\n",
    "        else:\n",
    "            gdf_tmp = gpd.read_file(shpfile, engine='pyogrio', use_arrow=True)\n",
    "            gdf['values'] += gdf_tmp['values']\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c47b63a1-cd34-4782-afe6-2410aa759c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.clip(gdf.to_crs(gdf_boundary.crs), gdf_boundary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2f0d38a-7131-44cf-8244-3390889e646e",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_folder = r'C:\\Users\\LeachJ\\Documents\\06_Oil Sands Monitoring Group\\gis'\n",
    "gdf.to_file(os.path.join(out_folder, total_precip_shapefile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4883f641-6daf-4692-9873-cd6727d45877",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow_stn = ['07BE001', '07DD001', '07DA001', '07DA018', '07DA040', '07DA033', '07CE013', '07CE002', '07CE007',\n",
    "            '07CD005', '07CD001', '07DB002', '07DB003', '07DA038', '07DA039', '07DA032', '07DA041', '07DC001',\n",
    "            '07DC003', '07CE008', '07CD004', '07CD008', '07CD009', '07CB002', '07DA027', '07CE005', '07DA026',\n",
    "            '07DA030', '07DB006', '07DB001', '07DC004', '07DA035', '07DA029', '07DA028', '07DA008', '07DA034',\n",
    "            '07CE003', '07DA007', '07DA042', '07DA044', '07DA006', '07CE010', '07DA037', '07DA045']\n",
    "\n",
    "level_stn = ['07CE001', '07DA024', '07DA023', '07DA025']\n",
    "\n",
    "stations = [*flow_stn, *level_stn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e84fdaf8-973b-4767-977c-4d56a92ba5b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "92.23139548301697\n"
     ]
    }
   ],
   "source": [
    "data_dict = {}\n",
    "tic = time.time()\n",
    "for timestep in timesteps:\n",
    "    shpfile = os.path.join(timeseriesfolder, f\"{timestep.strftime('%Y-%m-%d')}.shp\")\n",
    "    if os.path.exists(shpfile):\n",
    "        data_dict[timestep.strftime('%Y-%m-%d')] = gpd.read_file(shpfile, engine='pyogrio', use_arrow=True).to_crs(crs2)\n",
    "    else:\n",
    "        data_dict[timestep.strftime('%Y-%m-%d')] = np.nan\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9af9b909-d80a-4079-9b63-832874676a61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "81.70107793807983\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['datetime'] = pd.to_datetime(timesteps)\n",
    "tic = time.time()\n",
    "for station in stations:\n",
    "    shapefile = os.path.join(folder, station[:2], station, f\"{station}_DrainageBasin_BassinDeDrainage.shp\")\n",
    "    if not os.path.exists(shapefile):\n",
    "        shapefile = os.path.join(folder, station[:2], f'EC_{station}_1.shp')\n",
    "    if os.path.exists(shapefile):\n",
    "        gdf_basin = gpd.read_file(shapefile, engine='pyogrio', use_arrow=True).to_crs(crs2)\n",
    "        gdf_basin = gdf_basin.buffer(7000)  # 7 km buffer\n",
    "        \n",
    "    timeseries = []\n",
    "    for timestep in timesteps:\n",
    "        try:\n",
    "            gdf_tmp = gpd.clip(data_dict[timestep.strftime('%Y-%m-%d')], gdf_basin)\n",
    "            timeseries.append(np.mean(gdf_tmp['values']))  # equal weights to each grid... not exactly accurate\n",
    "        except TypeError:  # catch when data is missing / was replaced with nan\n",
    "            timeseries.append(data_dict[timestep.strftime('%Y-%m-%d')])\n",
    "\n",
    "    df[station] = timeseries\n",
    "        \n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4afb6822-17a8-45b1-8e66-6b568292dc22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.set_index('datetime').to_csv(f\"RDPAPrecip{np.unique(df['datetime'].dt.year)[0]}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7cb2ea5-5bb6-4866-a8f0-b5befe1a09e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.017035961151123047\n"
     ]
    }
   ],
   "source": [
    "tic = time.time()\n",
    "df_summary = pd.DataFrame()\n",
    "df_summary['StationID'] = stations\n",
    "df_summary['YEAR'] = np.unique(df['datetime'].dt.year)[0]\n",
    "\n",
    "tot_lst = []\n",
    "mis_lst = []\n",
    "for station in stations:\n",
    "    tot_lst.append(np.nansum(df[station]))\n",
    "    mis_lst.append(np.sum(np.isnan(df[station])))\n",
    "\n",
    "df_summary['VALUE'] = tot_lst\n",
    "df_summary['MISSING'] = mis_lst\n",
    "\n",
    "df_summary.to_csv(f\"CaPA_MAP_{df_summary['YEAR'][0]}-{df_summary['YEAR'][0]}.csv\", index=False)\n",
    "\n",
    "toc = time.time()\n",
    "print(toc-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313299c7-1456-4e92-b707-81d94059f339",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
